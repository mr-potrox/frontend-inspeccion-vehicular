{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f352c216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Configuraci√≥n del Entorno\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "print(f\"Fecha de ejecuci√≥n: {datetime.datetime.now()}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "try:\n",
    "    import ultralytics\n",
    "except ImportError:\n",
    "    print(\"Instalando Ultralytics YOLOv8...\")\n",
    "    !pip install ultralytics -q\n",
    "    import ultralytics\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import yaml\n",
    "import shutil\n",
    "\n",
    "print(f\"Ultralytics version: {ultralytics.__version__}\")\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU disponible: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU no disponible, se usar√° CPU.\")\n",
    "\n",
    "print(\"‚úÖ Entorno configurado.\")\n",
    "\n",
    "# Rutas del dataset y extracci√≥n\n",
    "zip_path = '/content/dataset_maestro_danos.zip'  # <-- Cambia aqu√≠ si tu archivo tiene otro nombre\n",
    "extract_path = '/content/dataset_damage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9cc9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 2: Descomprimir el Dataset\n",
    "import shutil as sh\n",
    "total, used, free = sh.disk_usage(\"/\")\n",
    "print(f\"Espacio libre: {free // (2**30)} GB\")\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\"No se encontr√≥ el archivo .zip en la ruta: {zip_path}\")\n",
    "\n",
    "if not zip_path.endswith('.zip'):\n",
    "    raise ValueError(\"El archivo debe ser un .zip\")\n",
    "\n",
    "print(f\"Descomprimiendo {zip_path} en {extract_path} ...\")\n",
    "!unzip -q \"{zip_path}\" -d \"{extract_path}\"\n",
    "print(f\"‚úÖ Dataset descomprimido en: {extract_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ffd37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 3: Localizar y validar el archivo data.yaml\n",
    "import yaml\n",
    "import glob\n",
    "from collections import Counter\n",
    "\n",
    "# Busca el archivo data.yaml en el directorio de extracci√≥n\n",
    "data_yaml_path = None\n",
    "for root, dirs, files in os.walk(extract_path):\n",
    "    if 'data.yaml' in files:\n",
    "        data_yaml_path = os.path.join(root, 'data.yaml')\n",
    "        break\n",
    "\n",
    "if not data_yaml_path:\n",
    "    raise FileNotFoundError(\"No se encontr√≥ el archivo data.yaml en el dataset descomprimido.\")\n",
    "\n",
    "with open(data_yaml_path, 'r') as file:\n",
    "    data_yaml_content = yaml.safe_load(file)\n",
    "    print(f\"Archivo data.yaml encontrado en: {data_yaml_path}\")\n",
    "    print(\"Clases detectadas:\", data_yaml_content.get('names', 'No se encontraron clases'))\n",
    "    assert 'train' in data_yaml_content and 'val' in data_yaml_content, \"data.yaml debe tener rutas 'train' y 'val'\"\n",
    "\n",
    "# Corrige rutas de train y val para que sean absolutas\n",
    "dataset_root_dir = os.path.dirname(data_yaml_path)\n",
    "for split in ['train', 'val', 'test']:\n",
    "    if split in data_yaml_content:\n",
    "        original_path = data_yaml_content[split]\n",
    "        absolute_path = os.path.join(dataset_root_dir, original_path) if not os.path.isabs(original_path) else original_path\n",
    "        data_yaml_content[split] = os.path.normpath(absolute_path)\n",
    "\n",
    "# Guarda el YAML corregido\n",
    "with open(data_yaml_path, 'w') as file:\n",
    "    yaml.dump(data_yaml_content, file, default_flow_style=False)\n",
    "\n",
    "print(\"Rutas corregidas en data.yaml:\")\n",
    "print(yaml.dump(data_yaml_content, default_flow_style=False))\n",
    "\n",
    "# An√°lisis de distribuci√≥n de clases\n",
    "label_dir = data_yaml_content['train'].replace('images', 'labels')\n",
    "label_files = glob.glob(os.path.join(label_dir, '*.txt'))\n",
    "class_counts = Counter()\n",
    "for lbl in label_files:\n",
    "    with open(lbl) as f:\n",
    "        for line in f:\n",
    "            class_id = line.strip().split()[0]\n",
    "            class_counts[class_id] += 1\n",
    "print(\"Distribuci√≥n de clases en entrenamiento:\", dict(class_counts))\n",
    "\n",
    "train_images = glob.glob(os.path.join(data_yaml_content['train'], '*.*'))\n",
    "val_images = glob.glob(os.path.join(data_yaml_content['val'], '*.*'))\n",
    "print(f\"N√∫mero de im√°genes de entrenamiento encontradas: {len(train_images)}\")\n",
    "print(f\"N√∫mero de im√°genes de validaci√≥n encontradas: {len(val_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da1140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 4: Visualizaci√≥n r√°pida del dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Selecciona las primeras 5 im√°genes de entrenamiento\n",
    "img_files = glob.glob(os.path.join(data_yaml_content['train'], '*.jpg'))[:5]\n",
    "\n",
    "# Verifica si todas tienen su archivo de etiqueta correspondiente\n",
    "missing_labels = []\n",
    "for img_path in img_files:\n",
    "    lbl_path = img_path.replace('images', 'labels').replace('.jpg', '.txt')\n",
    "    if not os.path.exists(lbl_path):\n",
    "        missing_labels.append(img_path)\n",
    "\n",
    "if missing_labels:\n",
    "    print(\"Im√°genes sin etiqueta:\", missing_labels)\n",
    "else:\n",
    "    print(\"Todas las im√°genes seleccionadas tienen etiqueta.\")\n",
    "\n",
    "if img_files:\n",
    "    print(f\"Mostrando {len(img_files)} im√°genes de entrenamiento:\")\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i, img_path in enumerate(img_files):\n",
    "        img = Image.open(img_path)\n",
    "        plt.subplot(1, len(img_files), i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(os.path.basename(img_path))\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No se encontraron im√°genes de entrenamiento para mostrar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c189a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 5: Entrenamiento del modelo YOLOv8 para da√±os\n",
    "model_type = 'yolov8n.pt'  # Cambia a yolov8s.pt, yolov8m.pt, etc. si tienes m√°s recursos\n",
    "model = YOLO(model_type)\n",
    "\n",
    "print(\"\\nüöÄ Iniciando entrenamiento para detecci√≥n de da√±os...\")\n",
    "try:\n",
    "    results = model.train(\n",
    "        data=data_yaml_path,\n",
    "        epochs=150,\n",
    "        imgsz=640,\n",
    "        project='TFM_Models_Damage',\n",
    "        name='Damage_Detector',\n",
    "        batch=16,\n",
    "        patience=20,\n",
    "        optimizer='auto',\n",
    "        augment=True\n",
    "    )\n",
    "    print(\"\\n‚úÖ Entrenamiento de da√±os completado.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error durante el entrenamiento: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fb6134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 6: Reanudar un Entrenamiento Interrumpido\n",
    "import glob\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Usa la ruta correcta para el detector de da√±os\n",
    "run_dir = '/content/TFM_Models_Damage/Damage_Detector*'\n",
    "\n",
    "try:\n",
    "    run_folders = sorted(glob.glob(run_dir))\n",
    "    if not run_folders:\n",
    "        print(\"No se encontr√≥ ninguna carpeta de entrenamiento previa.\")\n",
    "    else:\n",
    "        latest_run_dir = run_folders[-1]\n",
    "        last_checkpoint_path = os.path.join(latest_run_dir, 'weights/last.pt')\n",
    "\n",
    "        if os.path.exists(last_checkpoint_path):\n",
    "            print(f\"Punto de control encontrado en: {last_checkpoint_path}\")\n",
    "            print(\"Reanudando el entrenamiento...\")\n",
    "            model = YOLO(last_checkpoint_path)\n",
    "            results = model.train(resume=True)\n",
    "            print(\"Entrenamiento reanudado y completado.\")\n",
    "        else:\n",
    "            print(f\"No se encontr√≥ el archivo 'last.pt' en la carpeta: {latest_run_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al intentar reanudar el entrenamiento: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c92216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 7: Evaluaci√≥n y Visualizaci√≥n de Resultados\n",
    "print(\"üìä Resultados de entrenamiento:\")\n",
    "metrics = results.results_dict if hasattr(results, 'results_dict') else results\n",
    "print(metrics)\n",
    "\n",
    "# Visualiza y guarda predicciones en im√°genes de validaci√≥n\n",
    "val_imgs = glob.glob(os.path.join(data_yaml_content['val'], '*.jpg'))[:3]\n",
    "if not val_imgs:\n",
    "    print(\"‚ö†Ô∏è No se encontraron im√°genes de validaci√≥n para mostrar predicciones.\")\n",
    "else:\n",
    "    for img_path in val_imgs:\n",
    "        pred = model.predict(img_path, conf=0.25, save=True)\n",
    "        pred[0].show()\n",
    "        pred[0].save(f\"pred_{os.path.basename(img_path)}\")\n",
    "        print(f\"Predicci√≥n guardada para {img_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0614780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 8: Exportar y Guardar el Modelo Entrenado\n",
    "best_model_path = '/content/TFM_Models_Damage/Damage_Detector/weights/best.pt'\n",
    "final_model_name = 'damage_detector_model.pt'\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    shutil.copy(best_model_path, f\"/content/{final_model_name}\")\n",
    "    print(f\"\\nüéâ ¬°Modelo final guardado como '{final_model_name}' en la carpeta principal de Colab!\")\n",
    "    print(\"Puedes descargarlo desde el panel de archivos a la izquierda.\")\n",
    "    exported_onnx = model.export(format='onnx')\n",
    "    print(f\"Modelo exportado a ONNX en: {exported_onnx}\")\n",
    "    exported_torchscript = model.export(format='torchscript')\n",
    "    print(f\"Modelo exportado a TorchScript en: {exported_torchscript}\")\n",
    "    print(f\"Tama√±o del modelo final: {os.path.getsize(best_model_path) / (1024*1024):.2f} MB\")\n",
    "else:\n",
    "    print(f\"‚ùå ERROR: No se encontr√≥ el archivo del modelo entrenado en {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f335c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso final: Visualizaci√≥n avanzada de m√©tricas y recomendaciones\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Mostrar mAP global y por clase si est√° disponible\n",
    "if hasattr(results, 'metrics'):\n",
    "    metrics_data = results.metrics\n",
    "    if 'map50' in metrics_data:\n",
    "        print(f\"mAP@0.5 global: {metrics_data['map50']:.3f}\")\n",
    "    if 'map50-95' in metrics_data:\n",
    "        print(f\"mAP@0.5:0.95 global: {metrics_data['map50-95']:.3f}\")\n",
    "    if 'map_per_class' in metrics_data and 'names' in metrics_data:\n",
    "        print(\"\\n--- mAP por clase ---\")\n",
    "        for i, name in enumerate(metrics_data['names']):\n",
    "            print(f\"{name}: {metrics_data['map_per_class'][i]:.3f}\")\n",
    "        # Gr√°fica de mAP por clase\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.bar(metrics_data['names'], metrics_data['map_per_class'])\n",
    "        plt.title('mAP por clase')\n",
    "        plt.ylabel('mAP')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "\n",
    "# Matriz de confusi√≥n si est√° disponible\n",
    "if hasattr(results, 'confusion_matrix'):\n",
    "    cm = results.confusion_matrix\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.imshow(cm, cmap='Blues')\n",
    "    plt.title('Matriz de confusi√≥n')\n",
    "    plt.xlabel('Predicci√≥n')\n",
    "    plt.ylabel('Real')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "# Ejemplo de visualizaci√≥n de predicciones dif√≠ciles (opcional)\n",
    "val_imgs = glob.glob(os.path.join(data_yaml_content['val'], '*.jpg'))[:3]\n",
    "if val_imgs:\n",
    "    print(\"\\nEjemplos de predicciones en im√°genes de validaci√≥n:\")\n",
    "    for img_path in val_imgs:\n",
    "        pred = model.predict(img_path, conf=0.25)\n",
    "        pred[0].show()\n",
    "\n",
    "# Recomendaci√≥n profesional\n",
    "print(\"\\n‚úÖ Revisi√≥n final completada.\")\n",
    "print(\"- Analiza las clases con menor mAP para mejorar el dataset o ajustar hiperpar√°metros.\")\n",
    "print(\"- Usa la matriz de confusi√≥n para identificar errores frecuentes entre clases.\")\n",
    "print(\"- Guarda estos gr√°ficos y m√©tricas para tu informe o documentaci√≥n.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
