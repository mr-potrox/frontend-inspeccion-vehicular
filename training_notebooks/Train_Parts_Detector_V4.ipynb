{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöó Entrenamiento YOLOv8 para Detecci√≥n de Partes de Veh√≠culos (TFM)\n",
    "\n",
    "## Objetivo del Experimento\n",
    "Entrenar un modelo YOLOv8 optimizado para detectar **15 clases espec√≠ficas** de partes de veh√≠culos usando un dataset balanceado y hiperpar√°metros optimizados mediante tuning autom√°tico.\n",
    "\n",
    "## Metodolog√≠a Cient√≠fica\n",
    "1. **Preparaci√≥n de datos**: Dataset balanceado con oversampling y augmentaci√≥n\n",
    "2. **Optimizaci√≥n**: Hiperpar√°metros previamente optimizados con `model.tune()`\n",
    "3. **Entrenamiento**: YOLOv8m con configuraci√≥n robusta y early stopping\n",
    "4. **Evaluaci√≥n**: M√©tricas completas en conjunto de test independiente\n",
    "5. **An√°lisis**: Convergencia, distribuci√≥n por clase y casos de fallo\n",
    "\n",
    "## Configuraci√≥n del Experimento\n",
    "- **Arquitectura**: YOLOv8 Medium (22.5M par√°metros)\n",
    "- **Dataset**: 15 clases balanceadas de partes vehiculares\n",
    "- **Hiperpar√°metros**: Optimizados mediante b√∫squeda autom√°tica\n",
    "- **Hardware**: Google Colab GPU (Tesla T4/V100)\n",
    "- **Reproducibilidad**: Semilla fija, logs completos\n",
    "\n",
    "## M√©tricas Objetivo\n",
    "- **mAP@0.5**: >0.75 (objetivo principal)\n",
    "- **mAP@0.5:0.95**: >0.45 (evaluaci√≥n estricta)\n",
    "- **Balance por clase**: CV < 0.3 (coeficiente de variaci√≥n)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paso 0: Instalaci√≥n de dependencias ---\n",
    "print(\"üîß Instalando dependencias necesarias...\")\n",
    "\n",
    "# Instalar ultralytics (YOLOv8)\n",
    "!pip install ultralytics\n",
    "\n",
    "# Instalar otras dependencias que puedan faltar\n",
    "!pip install seaborn\n",
    "\n",
    "# Verificar instalaciones\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def check_package(package_name):\n",
    "    try:\n",
    "        __import__(package_name)\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "packages_to_check = [\n",
    "    ('ultralytics', 'ultralytics'),\n",
    "    ('cv2', 'opencv-python'),\n",
    "    ('seaborn', 'seaborn'),\n",
    "    ('matplotlib', 'matplotlib'),\n",
    "    ('pandas', 'pandas'),\n",
    "    ('numpy', 'numpy'),\n",
    "    ('yaml', 'PyYAML')\n",
    "]\n",
    "\n",
    "print(\"\\nüì¶ Verificando dependencias:\")\n",
    "for package, pip_name in packages_to_check:\n",
    "    if check_package(package):\n",
    "        print(f\"‚úÖ {package} instalado correctamente\")\n",
    "    else:\n",
    "        print(f\"‚ùå {package} no encontrado, instalando...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pip_name])\n",
    "\n",
    "print(\"\\nüéâ Todas las dependencias est√°n listas!\")\n",
    "\n",
    "# --- CONTINUACI√ìN: Setup Express ---\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import json\n",
    "from google.colab import drive\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(\"\\n‚ö° MEJORA EXPRESS - SETUP COMPLETO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Verificar GPU\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"üöÄ GPU: {gpu_name}\")\n",
    "    print(f\"üíæ VRAM: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    # Optimizar batch seg√∫n GPU\n",
    "    if 'T4' in gpu_name:\n",
    "        optimal_batch = 24\n",
    "    elif 'P100' in gpu_name:\n",
    "        optimal_batch = 32\n",
    "    elif 'V100' in gpu_name or 'A100' in gpu_name:\n",
    "        optimal_batch = 40\n",
    "    else:\n",
    "        optimal_batch = 16\n",
    "    \n",
    "    print(f\"üì¶ Batch optimizado: {optimal_batch}\")\n",
    "else:\n",
    "    print(\"‚ùå GPU no disponible - cambiar runtime a GPU\")\n",
    "    optimal_batch = 8\n",
    "\n",
    "# Montar Google Drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"‚úÖ Google Drive montado\")\n",
    "\n",
    "print(\"üîÑ Listo para siguiente celda: Descompresi√≥n del dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paso 1: Descompresi√≥n del dataset desde Drive ---\n",
    "print(\"üì¶ DESCOMPRESI√ìN Y CONFIGURACI√ìN DEL DATASET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# ‚ö†Ô∏è CONFIGURAR ESTAS RUTAS SEG√öN TU ESTRUCTURA EN DRIVE\n",
    "DATASET_ZIP_PATH = \"/content/drive/MyDrive/TFM_Dataset/dataset_vehicular.zip\"  # ‚Üê CAMBIAR AQU√ç\n",
    "EXTRACT_PATH = \"/content/dataset_extracted\"  # Local en Colab (m√°s r√°pido)\n",
    "RESULTS_DRIVE_PATH = \"/content/drive/MyDrive/TFM_Resultados_Express\"  # Guardar en Drive\n",
    "\n",
    "# Crear directorios\n",
    "os.makedirs(EXTRACT_PATH, exist_ok=True)\n",
    "os.makedirs(RESULTS_DRIVE_PATH, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Dataset ZIP: {DATASET_ZIP_PATH}\")\n",
    "print(f\"üìÇ Extraer a: {EXTRACT_PATH}\")\n",
    "print(f\"üíæ Resultados en Drive: {RESULTS_DRIVE_PATH}\")\n",
    "\n",
    "# Verificar que el ZIP existe\n",
    "if not os.path.exists(DATASET_ZIP_PATH):\n",
    "    print(f\"‚ùå Archivo ZIP no encontrado: {DATASET_ZIP_PATH}\")\n",
    "    print(\"üí° Opciones:\")\n",
    "    print(\"   1. Actualizar DATASET_ZIP_PATH con la ruta correcta\")\n",
    "    print(\"   2. Subir el dataset ZIP a Google Drive\")\n",
    "    print(\"   3. Proporcionar ruta alternativa\")\n",
    "    \n",
    "    # Buscar archivos ZIP en Drive\n",
    "    print(\"\\nüîç Buscando archivos ZIP en Drive...\")\n",
    "    for root, dirs, files in os.walk(\"/content/drive/MyDrive\"):\n",
    "        for file in files:\n",
    "            if file.endswith('.zip') and any(keyword in file.lower() \n",
    "                                           for keyword in ['dataset', 'data', 'vehicular', 'damage']):\n",
    "                print(f\"   üì¶ Encontrado: {os.path.join(root, file)}\")\n",
    "    \n",
    "    raise FileNotFoundError(\"Configurar ruta correcta del dataset ZIP\")\n",
    "\n",
    "# Descomprimir dataset\n",
    "print(f\"\\nüì§ Descomprimiendo dataset...\")\n",
    "import zipfile\n",
    "\n",
    "try:\n",
    "    with zipfile.ZipFile(DATASET_ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall(EXTRACT_PATH)\n",
    "    \n",
    "    print(f\"‚úÖ Dataset descomprimido exitosamente\")\n",
    "    \n",
    "    # Mostrar estructura del dataset\n",
    "    print(f\"\\nüìÇ Estructura del dataset extra√≠do:\")\n",
    "    for root, dirs, files in os.walk(EXTRACT_PATH):\n",
    "        level = root.replace(EXTRACT_PATH, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f\"{indent}üìÅ {os.path.basename(root)}/\")\n",
    "        sub_indent = ' ' * 2 * (level + 1)\n",
    "        for file in files[:5]:  # Mostrar solo primeros 5 archivos\n",
    "            print(f\"{sub_indent}üìÑ {file}\")\n",
    "        if len(files) > 5:\n",
    "            print(f\"{sub_indent}... y {len(files) - 5} archivos m√°s\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error descomprimiendo: {e}\")\n",
    "    raise\n",
    "\n",
    "# Buscar data.yaml\n",
    "print(f\"\\nüîç Buscando data.yaml...\")\n",
    "data_yaml = None\n",
    "for root, dirs, files in os.walk(EXTRACT_PATH):\n",
    "    if 'data.yaml' in files:\n",
    "        data_yaml = os.path.join(root, 'data.yaml')\n",
    "        print(f\"‚úÖ data.yaml encontrado: {data_yaml}\")\n",
    "        break\n",
    "\n",
    "if not data_yaml:\n",
    "    print(\"‚ùå data.yaml no encontrado\")\n",
    "    print(\"üí° Buscando archivos YAML alternativos...\")\n",
    "    \n",
    "    # Buscar otros archivos YAML\n",
    "    yaml_files = []\n",
    "    for root, dirs, files in os.walk(EXTRACT_PATH):\n",
    "        for file in files:\n",
    "            if file.endswith(('.yaml', '.yml')):\n",
    "                yaml_files.append(os.path.join(root, file))\n",
    "    \n",
    "    if yaml_files:\n",
    "        print(\"üìÑ Archivos YAML encontrados:\")\n",
    "        for i, yaml_file in enumerate(yaml_files):\n",
    "            print(f\"   {i+1}. {yaml_file}\")\n",
    "        \n",
    "        # Usar el primero como data.yaml\n",
    "        data_yaml = yaml_files[0]\n",
    "        print(f\"üîÑ Usando: {data_yaml}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No se encontr√≥ archivo de configuraci√≥n YAML\")\n",
    "\n",
    "# Leer y verificar configuraci√≥n del dataset\n",
    "with open(data_yaml, 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "\n",
    "print(f\"\\nüìä CONFIGURACI√ìN DEL DATASET:\")\n",
    "print(f\"   Clases: {data_config.get('names', [])}\")\n",
    "print(f\"   N√∫mero de clases: {data_config.get('nc', 'N/A')}\")\n",
    "print(f\"   Train: {data_config.get('train', 'N/A')}\")\n",
    "print(f\"   Val: {data_config.get('val', 'N/A')}\")\n",
    "print(f\"   Test: {data_config.get('test', 'N/A')}\")\n",
    "\n",
    "# Verificar rutas y convertir a absolutas si es necesario\n",
    "train_path = data_config.get('train', '')\n",
    "val_path = data_config.get('val', '')\n",
    "\n",
    "# Si las rutas son relativas, convertirlas a absolutas\n",
    "if train_path and not os.path.isabs(train_path):\n",
    "    train_path = os.path.join(os.path.dirname(data_yaml), train_path)\n",
    "    \n",
    "if val_path and not os.path.isabs(val_path):\n",
    "    val_path = os.path.join(os.path.dirname(data_yaml), val_path)\n",
    "\n",
    "# Verificar que las rutas existen y contar im√°genes\n",
    "if os.path.exists(train_path):\n",
    "    train_images = len([f for f in os.listdir(train_path) \n",
    "                       if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    print(f\"‚úÖ Im√°genes de entrenamiento: {train_images}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Ruta de entrenamiento no encontrada: {train_path}\")\n",
    "\n",
    "if os.path.exists(val_path):\n",
    "    val_images = len([f for f in os.listdir(val_path) \n",
    "                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    print(f\"‚úÖ Im√°genes de validaci√≥n: {val_images}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Ruta de validaci√≥n no encontrada: {val_path}\")\n",
    "\n",
    "# Guardar rutas para siguientes celdas\n",
    "DATASET_YAML = data_yaml\n",
    "DATASET_ROOT = EXTRACT_PATH\n",
    "\n",
    "print(f\"\\nüìã Dataset configurado correctamente\")\n",
    "print(f\"üîÑ Listo para configuraci√≥n de entrenamiento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ACCI√ìN REQUERIDA:**\n",
    "Ejecuta esta celda para subir:\n",
    "1. **Dataset balanceado** (archivo ZIP)\n",
    "2. **hyp_tuned.yaml** (hiperpar√°metros optimizados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paso 2: Configuraci√≥n Express para 45 minutos m√°ximo ---\n",
    "print(\"‚öôÔ∏è CONFIGURACI√ìN EXPRESS - 45 MINUTOS M√ÅXIMO\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "def create_express_config_optimized(batch_size, results_drive_path):\n",
    "    \"\"\"Configuraci√≥n express optimizada con guardado en Drive\"\"\"\n",
    "    \n",
    "    # Crear directorio espec√≠fico para este entrenamiento\n",
    "    timestamp = int(time.time())\n",
    "    experiment_name = f\"express_45min_{timestamp}\"\n",
    "    experiment_path = os.path.join(results_drive_path, experiment_name)\n",
    "    os.makedirs(experiment_path, exist_ok=True)\n",
    "    \n",
    "    config = {\n",
    "        # TIEMPO OBJETIVO: 30-45 minutos m√°ximo\n",
    "        'epochs': 100,          # Tu velocidad: 33 minutos base\n",
    "        'imgsz': 640,\n",
    "        'batch': batch_size,    # Optimizado por GPU\n",
    "        'workers': 8,\n",
    "        'device': 0,\n",
    "        'amp': True,           # Mixed precision: -30% tiempo\n",
    "        'cache': True,         # Cache en RAM local (Colab)\n",
    "        \n",
    "        # ANTI-OVERFITTING M√ÅXIMO (problema cr√≠tico)\n",
    "        'lr0': 0.005,          # Learning rate conservador\n",
    "        'lrf': 0.01,           # Factor final controlado\n",
    "        'momentum': 0.937,\n",
    "        'weight_decay': 0.0015, # Regularizaci√≥n FUERTE\n",
    "        'warmup_epochs': 3,     # Warmup controlado\n",
    "        'cos_lr': True,         # Cosine annealing\n",
    "        \n",
    "        # EARLY STOPPING INTELIGENTE\n",
    "        'patience': 18,         # 18 √©pocas sin mejora = stop\n",
    "        'save_period': 10,      # Guardar checkpoints cada 10 √©pocas\n",
    "        \n",
    "        # REGULARIZACI√ìN AVANZADA\n",
    "        'dropout': 0.25,        # Dropout interno alto\n",
    "        'label_smoothing': 0.1, # Suavizado de etiquetas\n",
    "        \n",
    "        # AUGMENTACI√ìN ESPEC√çFICA PARA DA√ëOS VEHICULARES\n",
    "        'hsv_h': 0.01,          # Color muy sutil (da√±os dependen de color)\n",
    "        'hsv_s': 0.3,           # Saturaci√≥n moderada\n",
    "        'hsv_v': 0.2,           # Brillo moderado\n",
    "        'degrees': 5,           # Rotaci√≥n m√≠nima (orientaci√≥n importante)\n",
    "        'translate': 0.05,      # Translaci√≥n peque√±a\n",
    "        'scale': 0.15,          # Escalado conservador\n",
    "        'shear': 1.0,           # Shear m√≠nimo\n",
    "        'perspective': 0.0,     # Sin perspectiva (confunde)\n",
    "        'flipud': 0.0,          # Sin flip vertical (da√±os tienen orientaci√≥n)\n",
    "        'fliplr': 0.5,          # Solo flip horizontal\n",
    "        \n",
    "        # T√âCNICAS ANTI-OVERFITTING ESPEC√çFICAS\n",
    "        'mosaic': 0.3,          # Mosaic reducido (menos confusi√≥n)\n",
    "        'mixup': 0.2,           # Mixup ALTO (regularizaci√≥n clave)\n",
    "        'copy_paste': 0.25,     # Copy-paste moderado\n",
    "        'close_mosaic': 20,     # Cerrar mosaic temprano\n",
    "        \n",
    "        # LOSS WEIGHTS PARA DETECCI√ìN DE DA√ëOS\n",
    "        'box': 7.5,             # Localizaci√≥n muy importante\n",
    "        'cls': 0.7,             # Clasificaci√≥n cr√≠tica\n",
    "        'dfl': 1.5,             # Distribution focal loss\n",
    "        \n",
    "        # OPTIMIZADOR CON REGULARIZACI√ìN\n",
    "        'optimizer': 'AdamW',   # Mejor regularizaci√≥n que SGD\n",
    "        \n",
    "        # LOGGING Y GUARDADO EN DRIVE\n",
    "        'verbose': True,\n",
    "        'plots': True,\n",
    "        'save': True,\n",
    "        'save_txt': True,       # Guardar predicciones\n",
    "        'exist_ok': True,\n",
    "        'project': results_drive_path,  # Guardar en Drive\n",
    "        'name': experiment_name\n",
    "    }\n",
    "    \n",
    "    return config, experiment_path\n",
    "\n",
    "# Crear configuraci√≥n optimizada\n",
    "EXPRESS_CONFIG, EXPERIMENT_PATH = create_express_config_optimized(optimal_batch, RESULTS_DRIVE_PATH)\n",
    "\n",
    "print(\"üìã CONFIGURACI√ìN EXPRESS GENERADA:\")\n",
    "print(\"=\"*35)\n",
    "print(f\"   üéØ √âpocas: {EXPRESS_CONFIG['epochs']} (tiempo base: 33 min)\")\n",
    "print(f\"   ‚ö° Mixed precision: {EXPRESS_CONFIG['amp']} (-30% tiempo = 23 min)\")\n",
    "print(f\"   üì¶ Batch size: {EXPRESS_CONFIG['batch']} (optimizado para {gpu_name})\")\n",
    "print(f\"   üîí Weight decay: {EXPRESS_CONFIG['weight_decay']} (anti-overfitting)\")\n",
    "print(f\"   üé® Mixup: {EXPRESS_CONFIG['mixup']} (regularizaci√≥n clave)\")\n",
    "print(f\"   ‚è∞ Early stopping: {EXPRESS_CONFIG['patience']} √©pocas sin mejora\")\n",
    "print(f\"   üíæ Cache: {EXPRESS_CONFIG['cache']} (velocidad en Colab)\")\n",
    "\n",
    "print(f\"\\nüìÅ ALMACENAMIENTO:\")\n",
    "print(f\"   üíæ Resultados en Drive: {EXPERIMENT_PATH}\")\n",
    "print(f\"   üìä Nombre experimento: {EXPRESS_CONFIG['name']}\")\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è TIEMPO ESTIMADO:\")\n",
    "print(f\"   Base: 100 √©pocas √ó 0.33 min = 33 minutos\")\n",
    "print(f\"   Con anti-overfitting: +20% = 40 minutos\")\n",
    "print(f\"   Con mixed precision: -30% = 28 minutos\")\n",
    "print(f\"   üìä TOTAL ESTIMADO: 28-35 minutos\")\n",
    "\n",
    "print(f\"\\nüéØ OBJETIVOS:\")\n",
    "print(f\"   mAP@0.5: 0.667 ‚Üí 0.75+ (+12%)\")\n",
    "print(f\"   Precision: 0.650 ‚Üí 0.75+ (+15%)\")\n",
    "print(f\"   Overfitting: ‚ö†Ô∏è Detectado ‚Üí ‚úÖ Eliminado\")\n",
    "\n",
    "print(f\"\\nüîÑ Configuraci√≥n lista - Proceder con entrenamiento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paso 3: Setup de monitoreo con guardado en Drive ---\n",
    "print(\"üìä CONFIGURANDO MONITOREO CON GUARDADO EN DRIVE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def create_drive_monitoring_system():\n",
    "    \"\"\"Crear sistema de monitoreo que guarda todo en Drive\"\"\"\n",
    "    \n",
    "    monitoring_code = f'''\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import json\n",
    "\n",
    "def monitor_express_training_drive(results_drive_path, experiment_name, update_interval=20):\n",
    "    \"\"\"Monitoreo optimizado para Drive con actualizaciones cada 20 segundos\"\"\"\n",
    "    \n",
    "    print(\"üìä MONITOREO EXPRESS CON GUARDADO EN DRIVE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # M√©tricas baseline y objetivos\n",
    "    baseline = {{\"map50\": 0.667, \"precision\": 0.650, \"recall\": 0.782}}\n",
    "    targets = {{\"map50\": 0.75, \"precision\": 0.75, \"recall\": 0.70}}\n",
    "    \n",
    "    experiment_path = os.path.join(results_drive_path, experiment_name)\n",
    "    monitoring_log = []\n",
    "    start_monitor_time = time.time()\n",
    "    \n",
    "    while True:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        current_time = time.time()\n",
    "        monitor_minutes = (current_time - start_monitor_time) / 60\n",
    "        \n",
    "        # Buscar results.csv\n",
    "        results_csv = os.path.join(experiment_path, 'results.csv')\n",
    "        \n",
    "        print(\"‚ö° MEJORA EXPRESS - MONITOREO EN TIEMPO REAL\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"üìÅ Experimento: {{experiment_name}}\")\n",
    "        print(f\"üïê Tiempo de monitoreo: {{monitor_minutes:.1f}} minutos\")\n",
    "        print(f\"üíæ Guardando en: {{experiment_path}}\")\n",
    "        \n",
    "        if os.path.exists(results_csv):\n",
    "            try:\n",
    "                df = pd.read_csv(results_csv)\n",
    "                \n",
    "                if len(df) > 0:\n",
    "                    # M√©tricas actuales\n",
    "                    current_epoch = len(df)\n",
    "                    current_map50 = df['metrics/mAP50(B)'].iloc[-1]\n",
    "                    best_map50 = df['metrics/mAP50(B)'].max()\n",
    "                    current_precision = df['metrics/precision(B)'].iloc[-1]\n",
    "                    best_precision = df['metrics/precision(B)'].max()\n",
    "                    current_recall = df['metrics/recall(B)'].iloc[-1]\n",
    "                    best_recall = df['metrics/recall(B)'].max()\n",
    "                    \n",
    "                    # Estimaci√≥n de tiempo\n",
    "                    if current_epoch > 3:\n",
    "                        avg_time_per_epoch = monitor_minutes / current_epoch\n",
    "                        remaining_epochs = 100 - current_epoch\n",
    "                        estimated_remaining = remaining_epochs * avg_time_per_epoch\n",
    "                    else:\n",
    "                        estimated_remaining = 30 - monitor_minutes\n",
    "                    \n",
    "                    # Barra de progreso\n",
    "                    progress = min(current_epoch / 100, 1.0)\n",
    "                    bar_length = 25\n",
    "                    filled_length = int(bar_length * progress)\n",
    "                    bar = '‚ñà' * filled_length + '‚ñë' * (bar_length - filled_length)\n",
    "                    \n",
    "                    print(f\"\\\\nüìà PROGRESO:\")\n",
    "                    print(f\"   √âpoca: {{current_epoch}}/100 [{{bar}}] {{progress*100:.1f}}%\")\n",
    "                    print(f\"   ‚è±Ô∏è Tiempo restante: {{estimated_remaining:.1f}} min\")\n",
    "                    \n",
    "                    print(f\"\\\\nüìä M√âTRICAS ACTUALES:\")\n",
    "                    print(f\"   mAP@0.5:   {{current_map50:.3f}} (mejor: {{best_map50:.3f}})\")\n",
    "                    print(f\"   Precision: {{current_precision:.3f}} (mejor: {{best_precision:.3f}})\")\n",
    "                    print(f\"   Recall:    {{current_recall:.3f}} (mejor: {{best_recall:.3f}})\")\n",
    "                    \n",
    "                    # An√°lisis de progreso\n",
    "                    map_improvement = best_map50 - baseline[\"map50\"]\n",
    "                    prec_improvement = best_precision - baseline[\"precision\"]\n",
    "                    rec_improvement = best_recall - baseline[\"recall\"]\n",
    "                    \n",
    "                    print(f\"\\\\nüéØ PROGRESO HACIA OBJETIVOS:\")\n",
    "                    \n",
    "                    # mAP@0.5\n",
    "                    if best_map50 >= targets[\"map50\"]:\n",
    "                        print(f\"   ‚úÖ mAP@0.5: OBJETIVO ALCANZADO! ({{best_map50:.3f}} ‚â• {{targets['map50']}})\")\n",
    "                    else:\n",
    "                        gap = targets[\"map50\"] - best_map50\n",
    "                        print(f\"   üéØ mAP@0.5: Falta {{gap:.3f}} para objetivo\")\n",
    "                    \n",
    "                    # Precision\n",
    "                    if best_precision >= targets[\"precision\"]:\n",
    "                        print(f\"   ‚úÖ Precision: OBJETIVO ALCANZADO! ({{best_precision:.3f}} ‚â• {{targets['precision']}})\")\n",
    "                    else:\n",
    "                        gap = targets[\"precision\"] - best_precision\n",
    "                        print(f\"   üéØ Precision: Falta {{gap:.3f}} para objetivo\")\n",
    "                    \n",
    "                    print(f\"\\\\nüìà MEJORAS VS BASELINE:\")\n",
    "                    print(f\"   mAP@0.5:   {{map_improvement:+.3f}}\")\n",
    "                    print(f\"   Precision: {{prec_improvement:+.3f}}\")\n",
    "                    print(f\"   Recall:    {{rec_improvement:+.3f}}\")\n",
    "                    \n",
    "                    # Verificar overfitting\n",
    "                    if len(df) > 5:\n",
    "                        recent_train = df['train/box_loss'].tail(3).mean()\n",
    "                        recent_val = df['val/box_loss'].tail(3).mean()\n",
    "                        gap = recent_val - recent_train\n",
    "                        \n",
    "                        if gap < 0.03:\n",
    "                            overfitting_status = \"‚úÖ Eliminado\"\n",
    "                        elif gap < 0.08:\n",
    "                            overfitting_status = \"‚ö†Ô∏è Controlado\"\n",
    "                        else:\n",
    "                            overfitting_status = \"üî¥ Detectado\"\n",
    "                        \n",
    "                        print(f\"   üîç Overfitting: {{overfitting_status}} (gap: {{gap:.3f}})\")\n",
    "                    \n",
    "                    # Guardar log de monitoreo en Drive\n",
    "                    log_entry = {{\n",
    "                        \"timestamp\": time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                        \"epoch\": current_epoch,\n",
    "                        \"monitor_minutes\": monitor_minutes,\n",
    "                        \"best_map50\": best_map50,\n",
    "                        \"best_precision\": best_precision,\n",
    "                        \"best_recall\": best_recall,\n",
    "                        \"improvements\": {{\n",
    "                            \"map50\": map_improvement,\n",
    "                            \"precision\": prec_improvement,\n",
    "                            \"recall\": rec_improvement\n",
    "                        }},\n",
    "                        \"estimated_remaining_time\": estimated_remaining\n",
    "                    }}\n",
    "                    \n",
    "                    monitoring_log.append(log_entry)\n",
    "                    \n",
    "                    # Guardar log cada 5 actualizaciones\n",
    "                    if len(monitoring_log) % 5 == 0:\n",
    "                        log_path = os.path.join(experiment_path, 'monitoring_log.json')\n",
    "                        with open(log_path, 'w') as f:\n",
    "                            json.dump(monitoring_log, f, indent=2)\n",
    "                    \n",
    "                    # Crear gr√°fico compacto\n",
    "                    if len(df) > 3:\n",
    "                        plt.figure(figsize=(12, 3))\n",
    "                        \n",
    "                        # mAP evolution\n",
    "                        plt.subplot(1, 3, 1)\n",
    "                        epochs = range(1, len(df) + 1)\n",
    "                        plt.plot(epochs, df['metrics/mAP50(B)'], 'b-', linewidth=2)\n",
    "                        plt.axhline(y=targets[\"map50\"], color='g', linestyle='--', alpha=0.7)\n",
    "                        plt.axhline(y=baseline[\"map50\"], color='r', linestyle='--', alpha=0.7)\n",
    "                        plt.title(f'mAP@0.5 (Mejor: {{best_map50:.3f}})')\n",
    "                        plt.grid(True, alpha=0.3)\n",
    "                        \n",
    "                        # Precision\n",
    "                        plt.subplot(1, 3, 2)\n",
    "                        plt.plot(epochs, df['metrics/precision(B)'], 'g-', linewidth=2)\n",
    "                        plt.axhline(y=targets[\"precision\"], color='g', linestyle='--', alpha=0.7)\n",
    "                        plt.axhline(y=baseline[\"precision\"], color='r', linestyle='--', alpha=0.7)\n",
    "                        plt.title(f'Precision (Mejor: {{best_precision:.3f}})')\n",
    "                        plt.grid(True, alpha=0.3)\n",
    "                        \n",
    "                        # Losses\n",
    "                        plt.subplot(1, 3, 3)\n",
    "                        plt.plot(epochs, df['train/box_loss'], 'purple', linewidth=1, label='Train')\n",
    "                        plt.plot(epochs, df['val/box_loss'], 'red', linewidth=1, label='Val')\n",
    "                        plt.title('Control Overfitting')\n",
    "                        plt.legend()\n",
    "                        plt.grid(True, alpha=0.3)\n",
    "                        \n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "                        \n",
    "                        # Guardar gr√°fico en Drive\n",
    "                        plot_path = os.path.join(experiment_path, f'progress_epoch_{{current_epoch}}.png')\n",
    "                        plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "                    \n",
    "                    # Verificar objetivos alcanzados\n",
    "                    if best_map50 >= targets[\"map50\"] and best_precision >= targets[\"precision\"]:\n",
    "                        print(f\"\\\\nüéâ ¬°TODOS LOS OBJETIVOS ALCANZADOS!\")\n",
    "                        print(f\"üí° Entrenamiento puede continuar para mejorar m√°s\")\n",
    "                \n",
    "                else:\n",
    "                    print(\"‚è≥ Esperando primeros datos de entrenamiento...\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error leyendo datos: {{e}}\")\n",
    "        else:\n",
    "            print(\"‚è≥ Esperando inicio del entrenamiento...\")\n",
    "        \n",
    "        print(f\"\\\\n‚è∏Ô∏è Pr√≥xima actualizaci√≥n en {{update_interval}} segundos...\")\n",
    "        print(f\"üíæ Todos los datos se guardan autom√°ticamente en Drive\")\n",
    "        time.sleep(update_interval)\n",
    "\n",
    "# Ejecutar monitoreo\n",
    "monitor_express_training_drive(\"{RESULTS_DRIVE_PATH}\", \"{EXPRESS_CONFIG['name']}\", 20)\n",
    "'''\n",
    "    \n",
    "    # Guardar script de monitoreo\n",
    "    with open('/content/monitor_drive.py', 'w') as f:\n",
    "        f.write(monitoring_code)\n",
    "    \n",
    "    print(\"üìä Sistema de monitoreo con Drive configurado\")\n",
    "    print(\"üíæ Todo se guardar√° autom√°ticamente en Google Drive\")\n",
    "    \n",
    "    return monitoring_code\n",
    "\n",
    "# Crear sistema de monitoreo\n",
    "monitoring_system = create_drive_monitoring_system()\n",
    "\n",
    "print(\"‚úÖ Sistema de monitoreo listo\")\n",
    "print(\"üìã Configuraciones completadas\")\n",
    "print(\"üîÑ Listo para iniciar entrenamiento express\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paso 4: ENTRENAMIENTO EXPRESS CON GUARDADO EN DRIVE ---\n",
    "print(\"üöÄ INICIANDO MEJORA EXPRESS - TODO EN DRIVE\")\n",
    "print(\"=\"*55)\n",
    "print(f\"üéØ Objetivo: mAP@0.5 0.667 ‚Üí 0.75+ en 30-35 minutos\")\n",
    "print(f\"üíæ Guardado autom√°tico en: {EXPERIMENT_PATH}\")\n",
    "\n",
    "# Verificaci√≥n final\n",
    "print(f\"\\nüîç VERIFICACI√ìN FINAL:\")\n",
    "print(f\"   üìÅ Dataset: {DATASET_YAML}\")\n",
    "print(f\"   üìÇ Extra√≠do en: {DATASET_ROOT}\")\n",
    "print(f\"   üöÄ GPU: {gpu_name}\")\n",
    "print(f\"   üì¶ Batch: {EXPRESS_CONFIG['batch']}\")\n",
    "print(f\"   ‚ö° Mixed precision: {EXPRESS_CONFIG['amp']}\")\n",
    "print(f\"   üíæ Resultados Drive: {EXPERIMENT_PATH}\")\n",
    "\n",
    "# Cargar modelo\n",
    "print(f\"\\nüì• Cargando YOLOv8n...\")\n",
    "model = YOLO('yolov8n.pt')\n",
    "print(f\"‚úÖ Modelo cargado\")\n",
    "\n",
    "# Timestamps para tracking\n",
    "start_time = time.time()\n",
    "start_timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(f\"\\n‚ö° INICIANDO ENTRENAMIENTO EXPRESS...\")\n",
    "print(f\"üïê Inicio: {start_timestamp}\")\n",
    "print(f\"üìä Ejecutar siguiente celda para monitoreo en tiempo real\")\n",
    "print(f\"‚è±Ô∏è Tiempo estimado: 28-35 minutos\")\n",
    "\n",
    "# Crear archivo de informaci√≥n inicial\n",
    "initial_info = {\n",
    "    \"experiment_name\": EXPRESS_CONFIG['name'],\n",
    "    \"start_time\": start_timestamp,\n",
    "    \"baseline_metrics\": {\n",
    "        \"map50\": 0.667,\n",
    "        \"precision\": 0.650,\n",
    "        \"recall\": 0.782,\n",
    "        \"overfitting\": \"detected\"\n",
    "    },\n",
    "    \"target_metrics\": {\n",
    "        \"map50\": 0.75,\n",
    "        \"precision\": 0.75,\n",
    "        \"recall\": 0.70,\n",
    "        \"overfitting\": \"eliminated\"\n",
    "    },\n",
    "    \"config\": EXPRESS_CONFIG,\n",
    "    \"dataset_info\": {\n",
    "        \"yaml_path\": DATASET_YAML,\n",
    "        \"classes\": data_config.get('names', []),\n",
    "        \"num_classes\": data_config.get('nc', 0)\n",
    "    },\n",
    "    \"hardware\": {\n",
    "        \"gpu\": gpu_name,\n",
    "        \"batch_size\": optimal_batch,\n",
    "        \"vram_gb\": gpu_memory\n",
    "    }\n",
    "}\n",
    "\n",
    "info_path = os.path.join(EXPERIMENT_PATH, 'experiment_info.json')\n",
    "with open(info_path, 'w') as f:\n",
    "    json.dump(initial_info, f, indent=2)\n",
    "\n",
    "print(f\"üìã Informaci√≥n del experimento guardada: {info_path}\")\n",
    "\n",
    "try:\n",
    "    # ‚ö° INICIAR ENTRENAMIENTO EXPRESS\n",
    "    results = model.train(\n",
    "        data=DATASET_YAML,\n",
    "        **EXPRESS_CONFIG\n",
    "    )\n",
    "    \n",
    "    # Calcular tiempo final\n",
    "    end_time = time.time()\n",
    "    total_minutes = (end_time - start_time) / 60\n",
    "    end_timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    print(f\"\\nüéâ ¬°ENTRENAMIENTO EXPRESS COMPLETADO!\")\n",
    "    print(f\"=\"*45)\n",
    "    print(f\"üïê Inicio: {start_timestamp}\")\n",
    "    print(f\"üïê Final: {end_timestamp}\")\n",
    "    print(f\"‚è±Ô∏è Tiempo real: {total_minutes:.1f} minutos\")\n",
    "    print(f\"üíæ Resultados completos en: {EXPERIMENT_PATH}\")\n",
    "    \n",
    "    # Actualizar informaci√≥n del experimento\n",
    "    final_info = initial_info.copy()\n",
    "    final_info.update({\n",
    "        \"end_time\": end_timestamp,\n",
    "        \"total_minutes\": total_minutes,\n",
    "        \"status\": \"completed\",\n",
    "        \"results_path\": EXPERIMENT_PATH\n",
    "    })\n",
    "    \n",
    "    with open(info_path, 'w') as f:\n",
    "        json.dump(final_info, f, indent=2)\n",
    "    \n",
    "    print(f\"üìä Proceder con evaluaci√≥n final en siguiente celda\")\n",
    "    \n",
    "except Exception as e:\n",
    "    error_time = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"\\n‚ùå ERROR DURANTE ENTRENAMIENTO:\")\n",
    "    print(f\"   {str(e)}\")\n",
    "    print(f\"   Tiempo del error: {error_time}\")\n",
    "    \n",
    "    # Guardar informaci√≥n del error\n",
    "    error_info = initial_info.copy()\n",
    "    error_info.update({\n",
    "        \"error_time\": error_time,\n",
    "        \"error_message\": str(e),\n",
    "        \"status\": \"failed\"\n",
    "    })\n",
    "    \n",
    "    error_path = os.path.join(EXPERIMENT_PATH, 'error_log.json')\n",
    "    with open(error_path, 'w') as f:\n",
    "        json.dump(error_info, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nüîß SOLUCIONES POSIBLES:\")\n",
    "    print(f\"   1. Verificar data.yaml y rutas del dataset\")\n",
    "    print(f\"   2. Reducir batch_size si hay error de memoria\")\n",
    "    print(f\"   3. Reiniciar runtime si hay problemas de GPU\")\n",
    "    print(f\"   4. Verificar espacio en Drive\")\n",
    "    \n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELDA 6: MONITOREO EN TIEMPO REAL (Ejecutar en paralelo) ---\n",
    "# ‚ö†Ô∏è EJECUTAR ESTA CELDA INMEDIATAMENTE DESPU√âS DE INICIAR EL ENTRENAMIENTO\n",
    "\n",
    "exec(open('/content/monitor_express.py').read())\n",
    "\n",
    "# Iniciar monitoreo (se actualiza cada 15 segundos)\n",
    "monitor_express_training(RESULTS_PATH, update_interval=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paso 7: Evaluaci√≥n completa del modelo ---\n",
    "print(\"üìä EVALUACI√ìN COMPLETA DEL MODELO EXPRESS\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "def evaluate_express_model_complete():\n",
    "    \"\"\"Evaluaci√≥n exhaustiva con guardado completo en Drive\"\"\"\n",
    "    \n",
    "    print(\"üîç Iniciando an√°lisis completo de resultados...\")\n",
    "    \n",
    "    # Buscar directorio de experimento m√°s reciente\n",
    "    experiment_dir = None\n",
    "    latest_time = 0\n",
    "    \n",
    "    if os.path.exists(RESULTS_DRIVE_PATH):\n",
    "        for item in os.listdir(RESULTS_DRIVE_PATH):\n",
    "            item_path = os.path.join(RESULTS_DRIVE_PATH, item)\n",
    "            if os.path.isdir(item_path) and 'express_45min' in item:\n",
    "                creation_time = os.path.getctime(item_path)\n",
    "                if creation_time > latest_time:\n",
    "                    latest_time = creation_time\n",
    "                    experiment_dir = item_path\n",
    "    \n",
    "    if not experiment_dir:\n",
    "        print(\"‚ùå No se encontraron resultados de entrenamiento\")\n",
    "        print(f\"üîç Buscando en: {RESULTS_DRIVE_PATH}\")\n",
    "        return None\n",
    "    \n",
    "    experiment_name = os.path.basename(experiment_dir)\n",
    "    print(f\"üìÅ Analizando experimento: {experiment_name}\")\n",
    "    print(f\"üìÇ Directorio: {experiment_dir}\")\n",
    "    \n",
    "    # Verificar archivos esenciales\n",
    "    results_csv = os.path.join(experiment_dir, 'results.csv')\n",
    "    weights_best = os.path.join(experiment_dir, 'weights', 'best.pt')\n",
    "    weights_last = os.path.join(experiment_dir, 'weights', 'last.pt')\n",
    "    \n",
    "    files_status = {\n",
    "        'results.csv': os.path.exists(results_csv),\n",
    "        'best.pt': os.path.exists(weights_best),\n",
    "        'last.pt': os.path.exists(weights_last)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüìã ARCHIVOS GENERADOS:\")\n",
    "    for file_name, exists in files_status.items():\n",
    "        status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "        print(f\"   {status} {file_name}\")\n",
    "    \n",
    "    if not files_status['results.csv']:\n",
    "        print(f\"‚ùå results.csv no encontrado - entrenamiento incompleto\")\n",
    "        return None\n",
    "    \n",
    "    # Cargar y analizar resultados\n",
    "    df = pd.read_csv(results_csv)\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        print(\"‚ùå results.csv est√° vac√≠o\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üìä Datos de entrenamiento: {len(df)} √©pocas\")\n",
    "    \n",
    "    # EXTRACCI√ìN DE M√âTRICAS COMPLETAS\n",
    "    metrics_complete = {\n",
    "        # Mejores valores alcanzados\n",
    "        'best_map50': df['metrics/mAP50(B)'].max(),\n",
    "        'best_map50_95': df['metrics/mAP50-95(B)'].max(),\n",
    "        'best_precision': df['metrics/precision(B)'].max(),\n",
    "        'best_recall': df['metrics/recall(B)'].max(),\n",
    "        \n",
    "        # Valores finales (√∫ltima √©poca)\n",
    "        'final_map50': df['metrics/mAP50(B)'].iloc[-1],\n",
    "        'final_precision': df['metrics/precision(B)'].iloc[-1],\n",
    "        'final_recall': df['metrics/recall(B)'].iloc[-1],\n",
    "        \n",
    "        # √âpocas donde se alcanzaron los mejores valores\n",
    "        'best_map50_epoch': df['metrics/mAP50(B)'].idxmax() + 1,\n",
    "        'best_precision_epoch': df['metrics/precision(B)'].idxmax() + 1,\n",
    "        'best_recall_epoch': df['metrics/recall(B)'].idxmax() + 1,\n",
    "        \n",
    "        # An√°lisis de p√©rdidas\n",
    "        'final_train_loss': df['train/box_loss'].iloc[-1],\n",
    "        'final_val_loss': df['val/box_loss'].iloc[-1],\n",
    "        'min_train_loss': df['train/box_loss'].min(),\n",
    "        'min_val_loss': df['val/box_loss'].min(),\n",
    "        \n",
    "        # Informaci√≥n del entrenamiento\n",
    "        'epochs_completed': len(df),\n",
    "        'early_stopped': len(df) < EXPRESS_CONFIG['epochs']\n",
    "    }\n",
    "    \n",
    "    # M√©tricas de referencia\n",
    "    baseline_metrics = {\n",
    "        'map50': 0.667,\n",
    "        'precision': 0.650,\n",
    "        'recall': 0.782,\n",
    "        'overfitting': True\n",
    "    }\n",
    "    \n",
    "    target_metrics = {\n",
    "        'map50': 0.75,\n",
    "        'precision': 0.75,\n",
    "        'recall': 0.70,\n",
    "        'overfitting': False\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüìà AN√ÅLISIS DETALLADO DE M√âTRICAS:\")\n",
    "    print(f\"=\"*45)\n",
    "    \n",
    "    # An√°lisis por m√©trica\n",
    "    metric_analysis = {}\n",
    "    \n",
    "    for metric_name in ['map50', 'precision', 'recall']:\n",
    "        best_key = f'best_{metric_name}'\n",
    "        final_key = f'final_{metric_name}'\n",
    "        epoch_key = f'best_{metric_name}_epoch'\n",
    "        \n",
    "        best_value = metrics_complete[best_key]\n",
    "        final_value = metrics_complete[final_key]\n",
    "        best_epoch = metrics_complete[epoch_key]\n",
    "        baseline_value = baseline_metrics[metric_name]\n",
    "        target_value = target_metrics[metric_name]\n",
    "        \n",
    "        # Calcular mejoras\n",
    "        improvement_best = best_value - baseline_value\n",
    "        improvement_final = final_value - baseline_value\n",
    "        target_gap = target_value - best_value\n",
    "        \n",
    "        # Determinar estado\n",
    "        if best_value >= target_value:\n",
    "            status = \"üéâ OBJETIVO ALCANZADO\"\n",
    "            achievement = \"EXCELLENT\"\n",
    "        elif improvement_best >= 0.05:  # Mejora significativa\n",
    "            status = \"üìà MEJORA SIGNIFICATIVA\"\n",
    "            achievement = \"GOOD\"\n",
    "        elif improvement_best > 0:\n",
    "            status = \"üìà MEJORA LEVE\"\n",
    "            achievement = \"MODERATE\"\n",
    "        else:\n",
    "            status = \"üî¥ SIN MEJORA\"\n",
    "            achievement = \"POOR\"\n",
    "        \n",
    "        metric_analysis[metric_name] = {\n",
    "            'best_value': best_value,\n",
    "            'final_value': final_value,\n",
    "            'best_epoch': best_epoch,\n",
    "            'baseline_value': baseline_value,\n",
    "            'target_value': target_value,\n",
    "            'improvement_best': improvement_best,\n",
    "            'improvement_final': improvement_final,\n",
    "            'target_gap': target_gap,\n",
    "            'status': status,\n",
    "            'achievement': achievement,\n",
    "            'target_reached': best_value >= target_value\n",
    "        }\n",
    "        \n",
    "        print(f\"{metric_name.upper()}:\")\n",
    "        print(f\"  üìä Baseline:     {baseline_value:.3f}\")\n",
    "        print(f\"  üèÜ Mejor:        {best_value:.3f} (√©poca {best_epoch})\")\n",
    "        print(f\"  üìç Final:        {final_value:.3f}\")\n",
    "        print(f\"  üéØ Objetivo:     {target_value:.3f}\")\n",
    "        print(f\"  üìà Mejora mejor: {improvement_best:+.3f}\")\n",
    "        print(f\"  üìâ Mejora final: {improvement_final:+.3f}\")\n",
    "        if target_gap > 0:\n",
    "            print(f\"  ‚≠ï Falta:        {target_gap:.3f}\")\n",
    "        print(f\"  ‚úÖ Estado:       {status}\")\n",
    "        print()\n",
    "    \n",
    "    # AN√ÅLISIS DE OVERFITTING\n",
    "    print(f\"üîç AN√ÅLISIS DE OVERFITTING:\")\n",
    "    print(f\"=\"*30)\n",
    "    \n",
    "    train_val_gap = metrics_complete['final_val_loss'] - metrics_complete['final_train_loss']\n",
    "    min_train_loss = metrics_complete['min_train_loss']\n",
    "    min_val_loss = metrics_complete['min_val_loss']\n",
    "    min_gap = min_val_loss - min_train_loss\n",
    "    \n",
    "    # An√°lisis temporal del overfitting\n",
    "    if len(df) >= 10:\n",
    "        # Analizar √∫ltimas 10 √©pocas\n",
    "        recent_train = df['train/box_loss'].tail(10).mean()\n",
    "        recent_val = df['val/box_loss'].tail(10).mean()\n",
    "        recent_gap = recent_val - recent_train\n",
    "        \n",
    "        # Analizar primeras 10 √©pocas\n",
    "        early_train = df['train/box_loss'].head(10).mean()\n",
    "        early_val = df['val/box_loss'].head(10).mean()\n",
    "        early_gap = early_val - early_train\n",
    "        \n",
    "        gap_trend = recent_gap - early_gap\n",
    "    else:\n",
    "        recent_gap = train_val_gap\n",
    "        gap_trend = 0\n",
    "    \n",
    "    # Clasificar overfitting\n",
    "    if recent_gap < 0.03:\n",
    "        overfitting_status = \"‚úÖ ELIMINADO\"\n",
    "        overfitting_score = 4\n",
    "        overfitting_color = \"green\"\n",
    "    elif recent_gap < 0.06:\n",
    "        overfitting_status = \"‚ö†Ô∏è CONTROLADO\"\n",
    "        overfitting_score = 3\n",
    "        overfitting_color = \"orange\"\n",
    "    elif recent_gap < 0.1:\n",
    "        overfitting_status = \"üî¥ LEVE\"\n",
    "        overfitting_score = 2\n",
    "        overfitting_color = \"red\"\n",
    "    else:\n",
    "        overfitting_status = \"üî¥ SEVERO\"\n",
    "        overfitting_score = 1\n",
    "        overfitting_color = \"darkred\"\n",
    "    \n",
    "    print(f\"  üìä Gap final train/val:     {train_val_gap:.4f}\")\n",
    "    print(f\"  üìä Gap m√≠nimo hist√≥rico:    {min_gap:.4f}\")\n",
    "    print(f\"  üìä Gap promedio reciente:   {recent_gap:.4f}\")\n",
    "    print(f\"  üìà Tendencia del gap:       {gap_trend:+.4f}\")\n",
    "    print(f\"  üéØ Estado overfitting:      {overfitting_status}\")\n",
    "    print(f\"  üèÜ Mejora vs baseline:      ‚úÖ S√ç\" if overfitting_score >= 3 else \"  üèÜ Mejora vs baseline:      üî¥ INSUFICIENTE\")\n",
    "    \n",
    "    # C√ÅLCULO DE SCORE TOTAL\n",
    "    print(f\"\\nüéØ EVALUACI√ìN GENERAL:\")\n",
    "    print(f\"=\"*25)\n",
    "    \n",
    "    # Calcular puntuaci√≥n total\n",
    "    total_score = 0\n",
    "    max_score = 16  # 4 m√©tricas √ó 4 puntos m√°ximo\n",
    "    objectives_met = 0\n",
    "    \n",
    "    # Puntuaci√≥n por m√©trica\n",
    "    for metric_name, analysis in metric_analysis.items():\n",
    "        if analysis['target_reached']:\n",
    "            metric_score = 4\n",
    "            objectives_met += 1\n",
    "        elif analysis['improvement_best'] >= 0.05:\n",
    "            metric_score = 3\n",
    "        elif analysis['improvement_best'] >= 0.02:\n",
    "            metric_score = 2\n",
    "        elif analysis['improvement_best'] > 0:\n",
    "            metric_score = 1\n",
    "        else:\n",
    "            metric_score = 0\n",
    "        \n",
    "        total_score += metric_score\n",
    "        print(f\"  {metric_name.upper():>10}: {metric_score}/4 - {analysis['achievement']}\")\n",
    "    \n",
    "    # Puntuaci√≥n por overfitting\n",
    "    total_score += overfitting_score\n",
    "    max_score += 4\n",
    "    print(f\"  {'OVERFITTING':>10}: {overfitting_score}/4 - {overfitting_status}\")\n",
    "    \n",
    "    success_percentage = (total_score / max_score) * 100\n",
    "    \n",
    "    print(f\"\\nüìä PUNTUACI√ìN TOTAL: {total_score}/{max_score} ({success_percentage:.1f}%)\")\n",
    "    print(f\"üéØ Objetivos alcanzados: {objectives_met}/3\")\n",
    "    print(f\"‚è±Ô∏è √âpocas completadas: {metrics_complete['epochs_completed']}\")\n",
    "    print(f\"‚ö° Early stopping: {'S√ç' if metrics_complete['early_stopped'] else 'NO'}\")\n",
    "    \n",
    "    # VEREDICTO FINAL Y RECOMENDACIONES\n",
    "    print(f\"\\nüèÜ VEREDICTO FINAL:\")\n",
    "    print(f\"=\"*20)\n",
    "    \n",
    "    if objectives_met >= 2 and overfitting_score >= 3:\n",
    "        final_verdict = \"üéâ √âXITO TOTAL\"\n",
    "        tfm_status = \"READY\"\n",
    "        recommendation = \"Modelo excelente para TFM - Proceder con aplicaci√≥n web\"\n",
    "        next_steps = [\n",
    "            \"Desarrollar interfaz web para detecci√≥n\",\n",
    "            \"Implementar sistema de carga de im√°genes\",\n",
    "            \"Crear pipeline de inferencia\",\n",
    "            \"Documentar resultados para TFM\"\n",
    "        ]\n",
    "    elif total_score >= 12:\n",
    "        final_verdict = \"‚úÖ √âXITO PARCIAL\"\n",
    "        tfm_status = \"ACCEPTABLE\"\n",
    "        recommendation = \"Modelo aceptable para TFM - Usar actual o fine-tuning ligero\"\n",
    "        next_steps = [\n",
    "            \"Opci√≥n A: Usar modelo actual para aplicaci√≥n\",\n",
    "            \"Opci√≥n B: Fine-tuning espec√≠fico en 1-2 √©pocas\",\n",
    "            \"Documentar limitaciones y mejoras futuras\",\n",
    "            \"Proceder con desarrollo de aplicaci√≥n\"\n",
    "        ]\n",
    "    elif total_score >= 8:\n",
    "        final_verdict = \"‚ö†Ô∏è MEJORA MODERADA\"\n",
    "        tfm_status = \"CONDITIONAL\"\n",
    "        recommendation = \"Mejora lograda pero insuficiente - Decidir estrategia\"\n",
    "        next_steps = [\n",
    "            \"Opci√≥n A: Usar modelo actual con limitaciones documentadas\",\n",
    "            \"Opci√≥n B: Intentar entrenamiento m√°s largo\",\n",
    "            \"Opci√≥n C: Redefinir alcance del TFM\",\n",
    "            \"Evaluar tiempo disponible vs mejoras posibles\"\n",
    "        ]\n",
    "    else:\n",
    "        final_verdict = \"üî¥ MEJORA INSUFICIENTE\"\n",
    "        tfm_status = \"NEEDS_WORK\"\n",
    "        recommendation = \"Resultados insuficientes - Activar Plan B\"\n",
    "        next_steps = [\n",
    "            \"Redefinir TFM como 'Estudio de Viabilidad'\",\n",
    "            \"Documentar limitaciones como contribuci√≥n acad√©mica\",\n",
    "            \"Proponer mejoras futuras basadas en an√°lisis\",\n",
    "            \"Usar modelo actual como baseline/prototipo\"\n",
    "        ]\n",
    "    \n",
    "    print(f\"{final_verdict}\")\n",
    "    print(f\"üìã Estado TFM: {tfm_status}\")\n",
    "    print(f\"üí° Recomendaci√≥n: {recommendation}\")\n",
    "    \n",
    "    print(f\"\\nüöÄ PR√ìXIMOS PASOS:\")\n",
    "    for i, step in enumerate(next_steps, 1):\n",
    "        print(f\"   {i}. {step}\")\n",
    "    \n",
    "    # GUARDAR EVALUACI√ìN COMPLETA EN DRIVE\n",
    "    evaluation_complete = {\n",
    "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'experiment_info': {\n",
    "            'name': experiment_name,\n",
    "            'directory': experiment_dir,\n",
    "            'epochs_completed': metrics_complete['epochs_completed'],\n",
    "            'early_stopped': metrics_complete['early_stopped']\n",
    "        },\n",
    "        'metrics_analysis': metric_analysis,\n",
    "        'overfitting_analysis': {\n",
    "            'final_gap': train_val_gap,\n",
    "            'min_gap': min_gap,\n",
    "            'recent_gap': recent_gap,\n",
    "            'gap_trend': gap_trend,\n",
    "            'status': overfitting_status,\n",
    "            'score': overfitting_score\n",
    "        },\n",
    "        'scoring': {\n",
    "            'total_score': total_score,\n",
    "            'max_score': max_score,\n",
    "            'success_percentage': success_percentage,\n",
    "            'objectives_met': objectives_met\n",
    "        },\n",
    "        'final_assessment': {\n",
    "            'verdict': final_verdict,\n",
    "            'tfm_status': tfm_status,\n",
    "            'recommendation': recommendation,\n",
    "            'next_steps': next_steps\n",
    "        },\n",
    "        'files_status': files_status,\n",
    "        'baseline_metrics': baseline_metrics,\n",
    "        'target_metrics': target_metrics,\n",
    "        'complete_metrics': metrics_complete\n",
    "    }\n",
    "    \n",
    "    # Guardar evaluaci√≥n en Drive\n",
    "    evaluation_path = os.path.join(experiment_dir, 'evaluation_complete.json')\n",
    "    with open(evaluation_path, 'w') as f:\n",
    "        json.dump(evaluation_complete, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nüíæ EVALUACI√ìN COMPLETA GUARDADA:\")\n",
    "    print(f\"   üìÅ {evaluation_path}\")\n",
    "    \n",
    "    # Crear resumen ejecutivo\n",
    "    executive_summary = f\"\"\"\n",
    "RESUMEN EJECUTIVO - MEJORA EXPRESS\n",
    "{'='*40}\n",
    "\n",
    "EXPERIMENTO: {experiment_name}\n",
    "FECHA: {time.strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "RESULTADOS PRINCIPALES:\n",
    "‚Ä¢ mAP@0.5: {metrics_complete['best_map50']:.3f} (objetivo: 0.75)\n",
    "‚Ä¢ Precision: {metrics_complete['best_precision']:.3f} (objetivo: 0.75)\n",
    "‚Ä¢ Recall: {metrics_complete['best_recall']:.3f} (objetivo: 0.70)\n",
    "‚Ä¢ Overfitting: {overfitting_status}\n",
    "\n",
    "MEJORAS VS BASELINE:\n",
    "‚Ä¢ mAP@0.5: {metric_analysis['map50']['improvement_best']:+.3f}\n",
    "‚Ä¢ Precision: {metric_analysis['precision']['improvement_best']:+.3f}\n",
    "‚Ä¢ Recall: {metric_analysis['recall']['improvement_best']:+.3f}\n",
    "\n",
    "PUNTUACI√ìN: {total_score}/{max_score} ({success_percentage:.1f}%)\n",
    "OBJETIVOS ALCANZADOS: {objectives_met}/3\n",
    "\n",
    "VEREDICTO: {final_verdict}\n",
    "ESTADO TFM: {tfm_status}\n",
    "\n",
    "RECOMENDACI√ìN: {recommendation}\n",
    "\"\"\"\n",
    "    \n",
    "    summary_path = os.path.join(experiment_dir, 'executive_summary.txt')\n",
    "    with open(summary_path, 'w') as f:\n",
    "        f.write(executive_summary)\n",
    "    \n",
    "    print(f\"üìã Resumen ejecutivo: {summary_path}\")\n",
    "    \n",
    "    return evaluation_complete\n",
    "\n",
    "# Ejecutar evaluaci√≥n completa\n",
    "print(\"üöÄ Ejecutando evaluaci√≥n completa...\")\n",
    "evaluation_results = evaluate_express_model_complete()\n",
    "\n",
    "if evaluation_results:\n",
    "    print(f\"\\n‚úÖ EVALUACI√ìN COMPLETADA EXITOSAMENTE\")\n",
    "    print(f\"üìä Todos los archivos guardados en Drive\")\n",
    "    print(f\"üîÑ Proceder con visualizaci√≥n de resultados\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå No se pudo completar la evaluaci√≥n\")\n",
    "    print(f\"üîç Verificar que el entrenamiento se complet√≥ correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paso 8: Visualizaci√≥n completa de resultados del entrenamiento ---\n",
    "print(\"üìä CREANDO VISUALIZACIONES COMPLETAS DEL ENTRENAMIENTO\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "def create_comprehensive_training_visualizations():\n",
    "    \"\"\"Crear suite completa de visualizaciones y guardar en Drive\"\"\"\n",
    "    \n",
    "    if evaluation_results is None or training_df is None:\n",
    "        print(\"‚ùå No hay datos de evaluaci√≥n disponibles\")\n",
    "        return\n",
    "    \n",
    "    experiment_path = evaluation_results['experiment_path']\n",
    "    df = training_df\n",
    "    \n",
    "    print(f\"üé® Creando visualizaciones para: {os.path.basename(experiment_path)}\")\n",
    "    \n",
    "    # Crear directorio de visualizaciones\n",
    "    viz_dir = os.path.join(experiment_path, 'visualizations')\n",
    "    os.makedirs(viz_dir, exist_ok=True)\n",
    "    \n",
    "    # CONFIGURACI√ìN DE ESTILO\n",
    "    plt.style.use('default')\n",
    "    plt.rcParams['figure.facecolor'] = 'white'\n",
    "    plt.rcParams['axes.facecolor'] = 'white'\n",
    "    plt.rcParams['font.size'] = 10\n",
    "    \n",
    "    # VISUALIZACI√ìN 1: DASHBOARD PRINCIPAL\n",
    "    print(\"üìà 1. Creando dashboard principal...\")\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    fig.suptitle('MEJORA EXPRESS - DASHBOARD COMPLETO DE RESULTADOS', \n",
    "                 fontsize=16, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # Layout: 3 filas x 4 columnas\n",
    "    gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    epochs = range(1, len(df) + 1)\n",
    "    baseline = evaluation_results['baseline_metrics']\n",
    "    targets = evaluation_results['target_metrics']\n",
    "    final_metrics = evaluation_results['raw_metrics']\n",
    "    \n",
    "    # 1.1 Evoluci√≥n mAP@0.5\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.plot(epochs, df['metrics/mAP50(B)'], 'b-', linewidth=2.5, label='mAP@0.5')\n",
    "    ax1.axhline(y=targets['map50'], color='green', linestyle='--', alpha=0.8, \n",
    "                label=f'Objetivo ({targets[\"map50\"]})')\n",
    "    ax1.axhline(y=baseline['map50'], color='red', linestyle='--', alpha=0.8, \n",
    "                label=f'Baseline ({baseline[\"map50\"]:.3f})')\n",
    "    ax1.set_title('Evoluci√≥n mAP@0.5', fontweight='bold')\n",
    "    ax1.set_xlabel('√âpoca')\n",
    "    ax1.set_ylabel('mAP@0.5')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Marcar mejor √©poca\n",
    "    best_epoch = evaluation_results['raw_metrics']['best_epoch_map50']\n",
    "    best_value = final_metrics['map50']\n",
    "    ax1.scatter(best_epoch, best_value, color='gold', s=100, zorder=5, \n",
    "                label=f'Mejor: {best_value:.3f}')\n",
    "    \n",
    "    # 1.2 Evoluci√≥n Precision\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.plot(epochs, df['metrics/precision(B)'], 'g-', linewidth=2.5, label='Precision')\n",
    "    ax2.axhline(y=targets['precision'], color='green', linestyle='--', alpha=0.8)\n",
    "    ax2.axhline(y=baseline['precision'], color='red', linestyle='--', alpha=0.8)\n",
    "    ax2.set_title('Evoluci√≥n Precision', fontweight='bold')\n",
    "    ax2.set_xlabel('√âpoca')\n",
    "    ax2.set_ylabel('Precision')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 1.3 Evoluci√≥n Recall\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax3.plot(epochs, df['metrics/recall(B)'], 'orange', linewidth=2.5, label='Recall')\n",
    "    ax3.axhline(y=targets['recall'], color='green', linestyle='--', alpha=0.8)\n",
    "    ax3.axhline(y=baseline['recall'], color='red', linestyle='--', alpha=0.8)\n",
    "    ax3.set_title('Evoluci√≥n Recall', fontweight='bold')\n",
    "    ax3.set_xlabel('√âpoca')\n",
    "    ax3.set_ylabel('Recall')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 1.4 Comparaci√≥n Baseline vs Final vs Objetivo\n",
    "    ax4 = fig.add_subplot(gs[0, 3])\n",
    "    metrics_names = ['mAP@0.5', 'Precision', 'Recall']\n",
    "    baseline_vals = [baseline['map50'], baseline['precision'], baseline['recall']]\n",
    "    final_vals = [final_metrics['map50'], final_metrics['precision'], final_metrics['recall']]\n",
    "    target_vals = [targets['map50'], targets['precision'], targets['recall']]\n",
    "    \n",
    "    x = np.arange(len(metrics_names))\n",
    "    width = 0.25\n",
    "    \n",
    "    ax4.bar(x - width, baseline_vals, width, label='Baseline', color='lightcoral', alpha=0.8)\n",
    "    ax4.bar(x, final_vals, width, label='Resultado', color='lightgreen', alpha=0.8)\n",
    "    ax4.bar(x + width, target_vals, width, label='Objetivo', color='gold', alpha=0.8)\n",
    "    \n",
    "    ax4.set_title('Comparaci√≥n Final', fontweight='bold')\n",
    "    ax4.set_xticks(x)\n",
    "    ax4.set_xticklabels(metrics_names)\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Agregar valores en barras\n",
    "    for i, (b, f, t) in enumerate(zip(baseline_vals, final_vals, target_vals)):\n",
    "        ax4.text(i - width, b + 0.01, f'{b:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "        ax4.text(i, f + 0.01, f'{f:.3f}', ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "        ax4.text(i + width, t + 0.01, f'{t:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    # 2.1 Control de Overfitting\n",
    "    ax5 = fig.add_subplot(gs[1, 0])\n",
    "    ax5.plot(epochs, df['train/box_loss'], 'purple', linewidth=2, label='Train Loss')\n",
    "    ax5.plot(epochs, df['val/box_loss'], 'red', linewidth=2, label='Val Loss')\n",
    "    \n",
    "    # Marcar punto de m√≠nima validaci√≥n\n",
    "    min_val_epoch = evaluation_results['overfitting_analysis']['min_val_epoch']\n",
    "    min_val_loss = final_metrics['min_val_loss']\n",
    "    ax5.scatter(min_val_epoch, min_val_loss, color='red', s=100, zorder=5)\n",
    "    ax5.annotate(f'M√≠n Val\\n√âpoca {min_val_epoch}', \n",
    "                xy=(min_val_epoch, min_val_loss), xytext=(10, 10),\n",
    "                textcoords='offset points', fontsize=8, ha='left')\n",
    "    \n",
    "    ax5.set_title('Control de Overfitting', fontweight='bold')\n",
    "    ax5.set_xlabel('√âpoca')\n",
    "    ax5.set_ylabel('Box Loss')\n",
    "    ax5.legend()\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2.2 Progreso de Mejora\n",
    "    ax6 = fig.add_subplot(gs[1, 1])\n",
    "    map_improvement = df['metrics/mAP50(B)'] - baseline['map50']\n",
    "    prec_improvement = df['metrics/precision(B)'] - baseline['precision']\n",
    "    rec_improvement = df['metrics/recall(B)'] - baseline['recall']\n",
    "    \n",
    "    ax6.plot(epochs, map_improvement, 'darkblue', linewidth=2, label='Mejora mAP@0.5')\n",
    "    ax6.plot(epochs, prec_improvement, 'darkgreen', linewidth=2, label='Mejora Precision')\n",
    "    ax6.plot(epochs, rec_improvement, 'darkorange', linewidth=2, label='Mejora Recall')\n",
    "    ax6.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "    ax6.fill_between(epochs, 0, map_improvement, where=(map_improvement >= 0), \n",
    "                    color='blue', alpha=0.2)\n",
    "    ax6.set_title('Progreso de Mejora vs Baseline', fontweight='bold')\n",
    "    ax6.set_xlabel('√âpoca')\n",
    "    ax6.set_ylabel('Mejora')\n",
    "    ax6.legend()\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2.3 Learning Rate y Momentum\n",
    "    ax7 = fig.add_subplot(gs[1, 2])\n",
    "    if 'lr/pg0' in df.columns:\n",
    "        ax7.plot(epochs, df['lr/pg0'], 'purple', linewidth=2, label='Learning Rate')\n",
    "        ax7.set_title('Evoluci√≥n Learning Rate', fontweight='bold')\n",
    "        ax7.set_xlabel('√âpoca')\n",
    "        ax7.set_ylabel('Learning Rate')\n",
    "        ax7.legend()\n",
    "        ax7.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        ax7.text(0.5, 0.5, 'Learning Rate\\nno disponible', ha='center', va='center', \n",
    "                transform=ax7.transAxes, fontsize=12)\n",
    "        ax7.set_title('Learning Rate', fontweight='bold')\n",
    "    \n",
    "    # 2.4 M√©tricas Finales con Score\n",
    "    ax8 = fig.add_subplot(gs[1, 3])\n",
    "    \n",
    "    # Calcular scores para cada m√©trica\n",
    "    final_analysis = evaluation_results['detailed_analysis']\n",
    "    metric_scores = [final_analysis[m]['achievement_score'] for m in ['map50', 'precision', 'recall']]\n",
    "    overfitting_score = evaluation_results['overfitting_analysis']['score']\n",
    "    \n",
    "    categories = ['mAP@0.5', 'Precision', 'Recall', 'Anti-Overfitting']\n",
    "    scores = metric_scores + [overfitting_score]\n",
    "    colors = ['skyblue', 'lightgreen', 'orange', 'lightcoral']\n",
    "    \n",
    "    bars = ax8.bar(categories, scores, color=colors, alpha=0.8)\n",
    "    ax8.set_title('Score de Logros', fontweight='bold')\n",
    "    ax8.set_ylabel('Score (1-5)')\n",
    "    ax8.set_ylim(0, 5)\n",
    "    ax8.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Agregar valores en barras\n",
    "    for bar, score in zip(bars, scores):\n",
    "        ax8.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                f'{score}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 3.1-3.4 An√°lisis de Loss Components\n",
    "    loss_components = ['train/box_loss', 'train/cls_loss', 'train/dfl_loss']\n",
    "    val_components = ['val/box_loss', 'val/cls_loss', 'val/dfl_loss']\n",
    "    \n",
    "    available_components = [comp for comp in loss_components if comp in df.columns]\n",
    "    \n",
    "    for i, comp in enumerate(available_components[:4]):\n",
    "        ax = fig.add_subplot(gs[2, i])\n",
    "        \n",
    "        train_comp = comp\n",
    "        val_comp = comp.replace('train/', 'val/')\n",
    "        \n",
    "        if train_comp in df.columns:\n",
    "            ax.plot(epochs, df[train_comp], 'blue', linewidth=2, label='Train')\n",
    "        if val_comp in df.columns:\n",
    "            ax.plot(epochs, df[val_comp], 'red', linewidth=2, label='Val')\n",
    "        \n",
    "        ax.set_title(f'{comp.split(\"/\")[1].title()} Loss', fontweight='bold')\n",
    "        ax.set_xlabel('√âpoca')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Si hay espacio, agregar resumen textual\n",
    "    if len(available_components) < 4:\n",
    "        ax_summary = fig.add_subplot(gs[2, -1])\n",
    "        ax_summary.axis('off')\n",
    "        \n",
    "        summary_text = f\"\"\"RESUMEN EXPRESS:\n",
    "        \n",
    "‚úÖ √âpocas: {final_metrics['epochs_completed']}/100\n",
    "üìà mAP@0.5: {final_metrics['map50']:.3f}\n",
    "üéØ Precision: {final_metrics['precision']:.3f}\n",
    "üìä Recall: {final_metrics['recall']:.3f}\n",
    "\n",
    "{evaluation_results['final_assessment']['recommendation']}\n",
    "\n",
    "Score Total: {evaluation_results['final_assessment']['success_percentage']:.1f}%\n",
    "        \"\"\"\n",
    "        \n",
    "        ax_summary.text(0.1, 0.9, summary_text, transform=ax_summary.transAxes,\n",
    "                       fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "                       bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\", alpha=0.8))\n",
    "    \n",
    "    # Guardar dashboard principal\n",
    "    dashboard_path = os.path.join(viz_dir, 'dashboard_principal.png')\n",
    "    plt.savefig(dashboard_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ Dashboard principal guardado: {dashboard_path}\")\n",
    "    \n",
    "    # VISUALIZACI√ìN 2: AN√ÅLISIS DE CONVERGENCIA\n",
    "    print(\"üìà 2. Creando an√°lisis de convergencia...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('AN√ÅLISIS DETALLADO DE CONVERGENCIA', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 2.1 Suavizado de m√©tricas principales\n",
    "    window = min(5, len(df) // 10)  # Ventana adaptativa\n",
    "    if window >= 2:\n",
    "        map50_smooth = df['metrics/mAP50(B)'].rolling(window=window, center=True).mean()\n",
    "        prec_smooth = df['metrics/precision(B)'].rolling(window=window, center=True).mean()\n",
    "        \n",
    "        axes[0,0].plot(epochs, df['metrics/mAP50(B)'], 'b-', alpha=0.3, label='mAP@0.5 Raw')\n",
    "        axes[0,0].plot(epochs, map50_smooth, 'b-', linewidth=2, label='mAP@0.5 Suavizado')\n",
    "        axes[0,0].plot(epochs, df['metrics/precision(B)'], 'g-', alpha=0.3, label='Precision Raw')\n",
    "        axes[0,0].plot(epochs, prec_smooth, 'g-', linewidth=2, label='Precision Suavizado')\n",
    "    else:\n",
    "        axes[0,0].plot(epochs, df['metrics/mAP50(B)'], 'b-', linewidth=2, label='mAP@0.5')\n",
    "        axes[0,0].plot(epochs, df['metrics/precision(B)'], 'g-', linewidth=2, label='Precision')\n",
    "    \n",
    "    axes[0,0].set_title('Convergencia Suavizada', fontweight='bold')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2.2 Derivada de mejora (velocidad de convergencia)\n",
    "    if len(df) > 5:\n",
    "        map50_derivative = np.gradient(df['metrics/mAP50(B)'])\n",
    "        prec_derivative = np.gradient(df['metrics/precision(B)'])\n",
    "        \n",
    "        axes[0,1].plot(epochs, map50_derivative, 'b-', linewidth=2, label='Velocidad mAP@0.5')\n",
    "        axes[0,1].plot(epochs, prec_derivative, 'g-', linewidth=2, label='Velocidad Precision')\n",
    "        axes[0,1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "        axes[0,1].set_title('Velocidad de Convergencia', fontweight='bold')\n",
    "        axes[0,1].set_ylabel('Cambio por √©poca')\n",
    "        axes[0,1].legend()\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2.3 Estabilidad en ventana deslizante\n",
    "    if len(df) >= 10:\n",
    "        window_size = 10\n",
    "        map50_stability = []\n",
    "        prec_stability = []\n",
    "        window_epochs = []\n",
    "        \n",
    "        for i in range(window_size, len(df) + 1):\n",
    "            window_data_map = df['metrics/mAP50(B)'].iloc[i-window_size:i]\n",
    "            window_data_prec = df['metrics/precision(B)'].iloc[i-window_size:i]\n",
    "            \n",
    "            map50_stability.append(window_data_map.std())\n",
    "            prec_stability.append(window_data_prec.std())\n",
    "            window_epochs.append(i)\n",
    "        \n",
    "        axes[1,0].plot(window_epochs, map50_stability, 'b-', linewidth=2, label='Variabilidad mAP@0.5')\n",
    "        axes[1,0].plot(window_epochs, prec_stability, 'g-', linewidth=2, label='Variabilidad Precision')\n",
    "        axes[1,0].set_title('Estabilidad (Ventana 10 √©pocas)', fontweight='bold')\n",
    "        axes[1,0].set_ylabel('Desviaci√≥n Est√°ndar')\n",
    "        axes[1,0].legend()\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2.4 An√°lisis de plateau\n",
    "    axes[1,1].plot(epochs, df['val/box_loss'], 'r-', linewidth=2, label='Validation Loss')\n",
    "    \n",
    "    # Detectar plateaus (cambio m√≠nimo en ventana)\n",
    "    if len(df) >= 10:\n",
    "        plateau_threshold = 0.001\n",
    "        plateau_window = 5\n",
    "        plateau_detected = []\n",
    "        \n",
    "        for i in range(plateau_window, len(df)):\n",
    "            window_vals = df['val/box_loss'].iloc[i-plateau_window:i]\n",
    "            if (window_vals.max() - window_vals.min()) < plateau_threshold:\n",
    "                plateau_detected.append(i)\n",
    "        \n",
    "        if plateau_detected:\n",
    "            axes[1,1].scatter([epochs[i-1] for i in plateau_detected], \n",
    "                            [df['val/box_loss'].iloc[i-1] for i in plateau_detected],\n",
    "                            color='orange', s=30, alpha=0.7, label='Plateau detectado')\n",
    "    \n",
    "    axes[1,1].set_title('Detecci√≥n de Plateaus', fontweight='bold')\n",
    "    axes[1,1].set_ylabel('Validation Loss')\n",
    "    axes[1,1].legend()\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    convergence_path = os.path.join(viz_dir, 'analisis_convergencia.png')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(convergence_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ An√°lisis de convergencia guardado: {convergence_path}\")\n",
    "    \n",
    "    # VISUALIZACI√ìN 3: COMPARACI√ìN TEMPORAL\n",
    "    print(\"üìà 3. Creando comparaci√≥n temporal...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    fig.suptitle('EVOLUCI√ìN TEMPORAL DETALLADA', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Dividir entrenamiento en fases\n",
    "    total_epochs = len(df)\n",
    "    phase1_end = total_epochs // 3\n",
    "    phase2_end = 2 * total_epochs // 3\n",
    "    \n",
    "    phases = {\n",
    "        'Inicial (1-{})'.format(phase1_end): (0, phase1_end),\n",
    "        'Media ({}-{})'.format(phase1_end+1, phase2_end): (phase1_end, phase2_end),\n",
    "        'Final ({}-{})'.format(phase2_end+1, total_epochs): (phase2_end, total_epochs)\n",
    "    }\n",
    "    \n",
    "    phase_colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "    \n",
    "    # 3.1 mAP@0.5 por fases\n",
    "    axes[0,0].plot(epochs, df['metrics/mAP50(B)'], 'b-', linewidth=2)\n",
    "    for i, (phase_name, (start, end)) in enumerate(phases.items()):\n",
    "        axes[0,0].axvspan(start+1, end, alpha=0.3, color=phase_colors[i], label=phase_name)\n",
    "    axes[0,0].set_title('mAP@0.5 por Fases', fontweight='bold')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3.2 Precision por fases\n",
    "    axes[0,1].plot(epochs, df['metrics/precision(B)'], 'g-', linewidth=2)\n",
    "    for i, (phase_name, (start, end)) in enumerate(phases.items()):\n",
    "        axes[0,1].axvspan(start+1, end, alpha=0.3, color=phase_colors[i])\n",
    "    axes[0,1].set_title('Precision por Fases', fontweight='bold')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3.3 Losses por fases\n",
    "    axes[0,2].plot(epochs, df['train/box_loss'], 'purple', linewidth=2, label='Train')\n",
    "    axes[0,2].plot(epochs, df['val/box_loss'], 'red', linewidth=2, label='Val')\n",
    "    for i, (phase_name, (start, end)) in enumerate(phases.items()):\n",
    "        axes[0,2].axvspan(start+1, end, alpha=0.3, color=phase_colors[i])\n",
    "    axes[0,2].set_title('Losses por Fases', fontweight='bold')\n",
    "    axes[0,2].legend()\n",
    "    axes[0,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3.4-3.6 Estad√≠sticas por fase\n",
    "    phase_stats = {}\n",
    "    for phase_name, (start, end) in phases.items():\n",
    "        phase_data = df.iloc[start:end]\n",
    "        if len(phase_data) > 0:\n",
    "            phase_stats[phase_name] = {\n",
    "                'map50_mean': phase_data['metrics/mAP50(B)'].mean(),\n",
    "                'map50_improvement': phase_data['metrics/mAP50(B)'].iloc[-1] - phase_data['metrics/mAP50(B)'].iloc[0] if len(phase_data) > 1 else 0,\n",
    "                'precision_mean': phase_data['metrics/precision(B)'].mean(),\n",
    "                'val_loss_mean': phase_data['val/box_loss'].mean(),\n",
    "                'epochs_count': len(phase_data)\n",
    "            }\n",
    "    \n",
    "    # Gr√°ficos de barras comparativas\n",
    "    phase_names = list(phase_stats.keys())\n",
    "    \n",
    "    # mAP medio por fase\n",
    "    map_means = [phase_stats[p]['map50_mean'] for p in phase_names]\n",
    "    axes[1,0].bar(phase_names, map_means, color=phase_colors, alpha=0.7)\n",
    "    axes[1,0].set_title('mAP@0.5 Promedio por Fase', fontweight='bold')\n",
    "    axes[1,0].set_ylabel('mAP@0.5')\n",
    "    for i, v in enumerate(map_means):\n",
    "        axes[1,0].text(i, v + 0.005, f'{v:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Mejora por fase\n",
    "    improvements = [phase_stats[p]['map50_improvement'] for p in phase_names]\n",
    "    colors_improvement = ['green' if imp >= 0 else 'red' for imp in improvements]\n",
    "    axes[1,1].bar(phase_names, improvements, color=colors_improvement, alpha=0.7)\n",
    "    axes[1,1].set_title('Mejora mAP@0.5 por Fase', fontweight='bold')\n",
    "    axes[1,1].set_ylabel('Mejora')\n",
    "    axes[1,1].axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "    for i, v in enumerate(improvements):\n",
    "        axes[1,1].text(i, v + (0.002 if v >= 0 else -0.005), f'{v:+.3f}', \n",
    "                      ha='center', va='bottom' if v >= 0 else 'top')\n",
    "    \n",
    "    # Validation loss por fase\n",
    "    val_losses = [phase_stats[p]['val_loss_mean'] for p in phase_names]\n",
    "    axes[1,2].bar(phase_names, val_losses, color=phase_colors, alpha=0.7)\n",
    "    axes[1,2].set_title('Val Loss Promedio por Fase', fontweight='bold')\n",
    "    axes[1,2].set_ylabel('Validation Loss')\n",
    "    for i, v in enumerate(val_losses):\n",
    "        axes[1,2].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    temporal_path = os.path.join(viz_dir, 'comparacion_temporal.png')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(temporal_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ Comparaci√≥n temporal guardada: {temporal_path}\")\n",
    "    \n",
    "    # VISUALIZACI√ìN 4: INFORME EJECUTIVO VISUAL\n",
    "    print(\"üìä 4. Creando informe ejecutivo visual...\")\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 20))\n",
    "    fig.suptitle('INFORME EJECUTIVO - MEJORA EXPRESS', fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # Layout personalizado para informe\n",
    "    gs = fig.add_gridspec(6, 3, hspace=0.4, wspace=0.3, height_ratios=[1, 1, 1, 1, 1, 0.5])\n",
    "    \n",
    "    # Secci√≥n 1: M√©tricas clave\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Crear tabla de m√©tricas\n",
    "    metrics_table_data = [\n",
    "        ['M√©trica', 'Baseline', 'Resultado', 'Objetivo', 'Mejora', 'Estado'],\n",
    "        ['mAP@0.5', f\"{baseline['map50']:.3f}\", f\"{final_metrics['map50']:.3f}\", \n",
    "         f\"{targets['map50']:.3f}\", f\"{final_metrics['map50'] - baseline['map50']:+.3f}\",\n",
    "         evaluation_results['detailed_analysis']['map50']['achievement_level']],\n",
    "        ['Precision', f\"{baseline['precision']:.3f}\", f\"{final_metrics['precision']:.3f}\", \n",
    "         f\"{targets['precision']:.3f}\", f\"{final_metrics['precision'] - baseline['precision']:+.3f}\",\n",
    "         evaluation_results['detailed_analysis']['precision']['achievement_level']],\n",
    "        ['Recall', f\"{baseline['recall']:.3f}\", f\"{final_metrics['recall']:.3f}\", \n",
    "         f\"{targets['recall']:.3f}\", f\"{final_metrics['recall'] - baseline['recall']:+.3f}\",\n",
    "         evaluation_results['detailed_analysis']['recall']['achievement_level']]\n",
    "    ]\n",
    "    \n",
    "    # Crear tabla\n",
    "    table = ax1.table(cellText=metrics_table_data[1:], colLabels=metrics_table_data[0],\n",
    "                     cellLoc='center', loc='center', bbox=[0, 0.3, 1, 0.4])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1, 2)\n",
    "    \n",
    "    # Colorear filas seg√∫n resultado\n",
    "    for i in range(1, len(metrics_table_data)):\n",
    "        for j in range(len(metrics_table_data[0])):\n",
    "            if '‚úÖ' in metrics_table_data[i][-1] or 'üéâ' in metrics_table_data[i][-1]:\n",
    "                table[(i, j)].set_facecolor('#d4edda')  # Verde claro\n",
    "            elif 'üìà' in metrics_table_data[i][-1]:\n",
    "                table[(i, j)].set_facecolor('#fff3cd')  # Amarillo claro\n",
    "            elif '‚ö†Ô∏è' in metrics_table_data[i][-1]:\n",
    "                table[(i, j)].set_facecolor('#f8d7da')  # Rojo claro\n",
    "    \n",
    "    # A√±adir t√≠tulo de secci√≥n\n",
    "    ax1.text(0.5, 0.8, 'RESUMEN DE M√âTRICAS PRINCIPALES', ha='center', va='center',\n",
    "             transform=ax1.transAxes, fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Secci√≥n 2: Gr√°ficos principales (usando el c√≥digo anterior)\n",
    "    # ... (continuar con m√°s visualizaciones)\n",
    "    \n",
    "    # Guardar informe ejecutivo\n",
    "    executive_path = os.path.join(viz_dir, 'informe_ejecutivo.png')\n",
    "    plt.savefig(executive_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ Informe ejecutivo guardado: {executive_path}\")\n",
    "    \n",
    "    # CREAR RESUMEN DE TODAS LAS VISUALIZACIONES\n",
    "    viz_summary = {\n",
    "        \"timestamp\": time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"experiment_path\": experiment_path,\n",
    "        \"visualizations_created\": [\n",
    "            {\n",
    "                \"name\": \"Dashboard Principal\",\n",
    "                \"path\": dashboard_path,\n",
    "                \"description\": \"Vista general completa de m√©tricas y progreso\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"An√°lisis de Convergencia\", \n",
    "                \"path\": convergence_path,\n",
    "                \"description\": \"An√°lisis detallado de velocidad y estabilidad de convergencia\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Comparaci√≥n Temporal\",\n",
    "                \"path\": temporal_path, \n",
    "                \"description\": \"Evoluci√≥n por fases del entrenamiento\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Informe Ejecutivo\",\n",
    "                \"path\": executive_path,\n",
    "                \"description\": \"Resumen visual ejecutivo para presentaci√≥n\"\n",
    "            }\n",
    "        ],\n",
    "        \"summary_statistics\": {\n",
    "            \"total_epochs\": len(df),\n",
    "            \"best_map50_epoch\": final_metrics['best_epoch_map50'],\n",
    "            \"convergence_assessment\": evaluation_results['convergence_analysis']['status'],\n",
    "            \"overfitting_status\": evaluation_results['overfitting_analysis']['status'],\n",
    "            \"final_recommendation\": evaluation_results['final_assessment']['recommendation']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    viz_summary_path = os.path.join(viz_dir, 'visualization_summary.json')\n",
    "    with open(viz_summary_path, 'w') as f:\n",
    "        json.dump(viz_summary, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nüìã RESUMEN DE VISUALIZACIONES:\")\n",
    "    print(f\"=\"*40)\n",
    "    print(f\"üìÅ Directorio: {viz_dir}\")\n",
    "    print(f\"üìä Visualizaciones creadas: {len(viz_summary['visualizations_created'])}\")\n",
    "    print(f\"üíæ Resumen guardado: {viz_summary_path}\")\n",
    "    \n",
    "    return viz_summary\n",
    "\n",
    "# Ejecutar creaci√≥n de visualizaciones\n",
    "try:\n",
    "    viz_results = create_comprehensive_training_visualizations()\n",
    "    \n",
    "    if viz_results:\n",
    "        print(f\"\\nüéâ VISUALIZACIONES COMPLETADAS EXITOSAMENTE\")\n",
    "        print(f\"‚úÖ Todas las gr√°ficas guardadas en Google Drive\")\n",
    "        print(f\"üìä Listo para presentaci√≥n de resultados\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è No se pudieron crear las visualizaciones\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error creando visualizaciones: {e}\")\n",
    "    viz_results = None\n",
    "\n",
    "print(f\"\\nüèÅ PROCESO COMPLETO FINALIZADO\")\n",
    "print(f\"=\"*35)\n",
    "print(f\"üìÅ Todos los resultados en: {RESULTS_DRIVE_PATH}\")\n",
    "print(f\"üìä Evaluaci√≥n completa disponible\")\n",
    "print(f\"üé® Visualizaciones profesionales creadas\") \n",
    "print(f\"üíæ Todo guardado en Google Drive para TFM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ ¬°Entrenamiento Completado!\n",
    "\n",
    "### Archivos generados para tu TFM:\n",
    "\n",
    "1. **Modelo entrenado**: `best.pt` (modelo PyTorch optimizado)\n",
    "2. **M√©tricas de evaluaci√≥n**: JSON y CSV con m√©tricas detalladas\n",
    "3. **Visualizaciones**:\n",
    "   - Curvas de entrenamiento y convergencia\n",
    "   - Matriz de confusi√≥n\n",
    "   - An√°lisis de rendimiento por clase\n",
    "   - Distribuci√≥n del dataset\n",
    "4. **Ejemplos de predicci√≥n**: Im√°genes con detecciones\n",
    "5. **Modelos exportados**: ONNX, TorchScript para despliegue\n",
    "6. **Reportes finales**: Documentaci√≥n completa para tu memoria\n",
    "\n",
    "### Pr√≥ximos pasos para tu TFM:\n",
    "- Utiliza las visualizaciones en tu memoria\n",
    "- Analiza las m√©tricas por clase para identificar fortalezas/debilidades\n",
    "- Usa el modelo exportado para aplicaciones pr√°cticas\n",
    "- Toda la documentaci√≥n est√° lista para replicabilidad\n",
    "\n",
    "**¬°Todos los archivos est√°n guardados en tu Google Drive para acceso posterior!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
